% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pass.R
\name{pass}
\alias{pass}
\title{Pass R Output to AI for Interpretation}
\usage{
pass(
  x,
  prompt = NULL,
  action = c("interpret", "explain", "write", "summarize", "critique", "suggest"),
  style = c("scientific", "simple", "detailed", "brief"),
  output = c("text", "markdown", "md", "latex", "html"),
  provider = c("anthropic", "openai", "gemini"),
  model = NULL,
  base_url = NULL,
  api_key = NULL,
  context = NULL,
  system_message = NULL,
  auto_local = TRUE,
  copy = FALSE,
  quiet = FALSE
)
}
\arguments{
\item{x}{Any R object to interpret (test result, model, data frame, etc.)}

\item{prompt}{Custom prompt to use. If NULL, builds from action and style.}

\item{action}{What to do with the output:
\itemize{
  \item `"interpret"` (default): Interpret the statistical results
  \item `"explain"`: Explain what the analysis does and means
  \item `"write"`: Write publication-ready text (methods/results)
  \item `"summarize"`: Brief summary of key findings
  \item `"critique"`: Critical evaluation with limitations
  \item `"suggest"`: Suggest follow-up analyses
}}

\item{style}{Interpretation style:
\itemize{
  \item `"scientific"` (default): APA-style for academic papers
  \item `"simple"`: Plain language, no jargon
  \item `"detailed"`: Comprehensive with assumptions, limitations, caveats
    (default for `action = "write"`)
  \item `"brief"`: Just the key takeaway
}}

\item{output}{Output format:
\itemize{
  \item `"text"` (default): Plain text
  \item `"markdown"` or `"md"`: Markdown formatted
  \item `"latex"`: LaTeX formatted for papers
  \item `"html"`: HTML formatted
}}

\item{provider}{AI provider: `"anthropic"` (default), `"openai"`, or `"gemini"`}

\item{model}{Model to use. Defaults: `"claude-sonnet-4-20250514"` (Anthropic),
`"gpt-4o"` (OpenAI), `"gemini-2.5-flash"` (Gemini).}

\item{base_url}{Custom API base URL for OpenAI-compatible servers (e.g., LM Studio,
Ollama, vLLM). Example: `"http://127.0.0.1:1234"` for LM Studio. When set,
uses OpenAI-compatible format regardless of provider setting.}

\item{api_key}{API key. If NULL, checks environment variables
(`ANTHROPIC_API_KEY`, `OPENAI_API_KEY`, or `GEMINI_API_KEY`), then prompts interactively.
For local servers like LM Studio, use `api_key = "none"` or any string.}

\item{context}{Optional context about your study (e.g., "This is a study on
student learning outcomes with N=500 participants")}

\item{system_message}{Optional custom instructions for the AI (e.g., "Focus on
clinical implications", "Be more concise", "Emphasize effect sizes")}

\item{auto_local}{Logical. Automatically detect and use local AI servers
(LM Studio on port 1234, Ollama on port 11434)? Default: TRUE.
Set to FALSE to force using cloud providers.}

\item{copy}{Logical. Copy result to clipboard? Default: FALSE}

\item{quiet}{Logical. Suppress messages? Default: FALSE}
}
\value{
Character string with the AI interpretation (invisibly).
  Also prints the interpretation.
}
\description{
Pipes any R output (test results, model summaries, tables) to an AI model
for scientific interpretation. Perfect for getting publication-ready
interpretations of statistical results.
}
\details{
On first use, you'll be prompted to enter your API key. The key is stored
in your R environment for the session. To persist it, add to your .Renviron:
```
ANTHROPIC_API_KEY=your-key-here
# or
OPENAI_API_KEY=your-key-here
```
}
\examples{
\dontrun{
# Basic usage - pipe test results
t.test(mpg ~ am, data = mtcars) |> pass()

# With context
cor.test(mtcars$mpg, mtcars$hp) |>
  pass(context = "Studying fuel efficiency in 1974 automobiles")

# Different actions
lm(mpg ~ wt + hp, data = mtcars) |> summary() |> pass(action = "write")
chisq.test(mtcars$cyl, mtcars$am) |> pass(action = "explain", style = "simple")

# Get LaTeX output for paper
aov(mpg ~ factor(cyl), data = mtcars) |> summary() |>
  pass(action = "write", output = "latex")

# Critique an analysis
lm(mpg ~ ., data = mtcars) |> summary() |> pass(action = "critique")

# Custom prompt (specific request to the AI)
my_results |> pass(prompt = "Focus only on the interaction effects")

# Custom context (about your study)
t.test(score ~ group, data = mydata) |>
  pass(context = "RCT comparing drug vs placebo, N=200 patients with diabetes")

# Custom system message (instructions for the AI)
my_results |> pass(system_message = "Focus on clinical implications and effect sizes")

# Combine all customizations
lm(outcome ~ treatment * age, data = mydata) |> summary() |>
  pass(
    action = "write",
    context = "Phase 3 clinical trial for hypertension medication",
    system_message = "Emphasize clinical significance over statistical significance",
    prompt = "Pay special attention to the treatment-age interaction"
  )
}

}
